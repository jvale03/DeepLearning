{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv(\"../../datasets/final_dataset.csv\")\n",
    "\n",
    "# First split: train and test\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    dataset[\"Text\"], dataset[\"Label\"], test_size=0.2, random_state=42, stratify=dataset[\"Label\"]\n",
    ")\n",
    "\n",
    "# Second split: train and validation\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_texts, train_labels, test_size=0.2, random_state=42, stratify=train_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the data using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "\n",
    "X_train = vectorizer.fit_transform(train_texts)\n",
    "X_val = vectorizer.transform(val_texts)\n",
    "X_test = vectorizer.transform(test_texts)\n",
    "\n",
    "y_train = np.array(train_labels)\n",
    "y_val = np.array(val_labels)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.9877\n",
      "Test accuracy: 0.9815\n"
     ]
    }
   ],
   "source": [
    "# Create and train the Logistic Regression model\n",
    "log_reg_model = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('log_reg', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "log_reg_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "val_predictions = log_reg_model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "print(f\"Validation accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "test_predictions = log_reg_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5750\n",
      "\n",
      "Misclassified Samples:\n",
      "    Label  Prediction Label_actual\n",
      "2   Human    0.002311           AI\n",
      "5   Human    0.000043           AI\n",
      "6   Human    0.001837           AI\n",
      "9   Human    0.099504           AI\n",
      "10  Human    0.135632           AI\n",
      "11  Human    0.159898           AI\n",
      "12  Human    0.003541           AI\n",
      "13  Human    0.002768           AI\n",
      "18  Human    0.022847           AI\n",
      "22  Human    0.000088           AI\n",
      "24  Human    0.014780           AI\n",
      "28  Human    0.000171           AI\n",
      "34  Human    0.196442           AI\n",
      "35  Human    0.159667           AI\n",
      "37  Human    0.039608           AI\n",
      "38  Human    0.035902           AI\n",
      "39  Human    0.099126           AI\n",
      "45  Human    0.470698           AI\n",
      "50     AI    0.547938        Human\n",
      "51  Human    0.029603           AI\n",
      "53  Human    0.010637           AI\n",
      "55  Human    0.167861           AI\n",
      "57  Human    0.002813           AI\n",
      "59  Human    0.002952           AI\n",
      "61  Human    0.151567           AI\n",
      "63  Human    0.009951           AI\n",
      "65  Human    0.356270           AI\n",
      "67  Human    0.007030           AI\n",
      "69  Human    0.001739           AI\n",
      "71  Human    0.073091           AI\n",
      "73  Human    0.396898           AI\n",
      "75  Human    0.006229           AI\n",
      "77  Human    0.232798           AI\n",
      "79  Human    0.000026           AI\n"
     ]
    }
   ],
   "source": [
    "# Load new data\n",
    "new_data = pd.read_csv(\"../../datasets/validation_dataset.csv\", delimiter=\";\")\n",
    "\n",
    "# Transform new data using the trained vectorizer\n",
    "X_new = vectorizer.transform(new_data[\"Text\"])\n",
    "\n",
    "# Make predictions using the trained logistic regression model\n",
    "predictions = log_reg_model.predict_proba(X_new)[:, 1]  # Get probability for the positive class\n",
    "\n",
    "# Convert predictions to labels based on threshold\n",
    "labels = [\"AI\" if pred > 0.5 else \"Human\" for pred in predictions]\n",
    "\n",
    "# Create output DataFrame with predictions\n",
    "output_df = pd.DataFrame({\n",
    "    \"Label\": labels,\n",
    "    \"Prediction\": predictions\n",
    "})\n",
    "\n",
    "# Load the ground truth labels (from the same dataset)\n",
    "ground_truth = new_data[\"Label\"]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (output_df[\"Label\"] == ground_truth).mean()\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Merge predictions with ground truth for comparison\n",
    "comparison_df = output_df.copy()\n",
    "comparison_df[\"Label_actual\"] = ground_truth\n",
    "\n",
    "# Show misclassified samples\n",
    "misclassified = comparison_df[comparison_df[\"Label\"] != comparison_df[\"Label_actual\"]]\n",
    "print(\"\\nMisclassified Samples:\")\n",
    "print(misclassified)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
