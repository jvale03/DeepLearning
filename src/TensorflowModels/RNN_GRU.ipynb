{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv(\"../../datasets/final_dataset.csv\")\n",
    "\n",
    "# First split: train and test\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    dataset[\"Text\"], dataset[\"Label\"], test_size=0.2, random_state=42, stratify=dataset[\"Label\"]\n",
    ")\n",
    "\n",
    "# Second split: train and validation\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_texts, train_labels, test_size=0.2, random_state=42, stratify=train_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the data\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(train_texts)\n",
    "X_val_seq = tokenizer.texts_to_sequences(val_texts)\n",
    "X_test_seq = tokenizer.texts_to_sequences(test_texts)\n",
    "\n",
    "X_train = pad_sequences(X_train_seq, maxlen=100)\n",
    "X_val = pad_sequences(X_val_seq, maxlen=100)\n",
    "X_test = pad_sequences(X_test_seq, maxlen=100)\n",
    "\n",
    "y_train = np.array(train_labels)\n",
    "y_val = np.array(val_labels)\n",
    "y_test = np.array(test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.5172 - loss: 1.0151 - val_accuracy: 0.5424 - val_loss: 0.9222 - learning_rate: 2.0000e-04\n",
      "Epoch 2/15\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 52ms/step - accuracy: 0.5263 - loss: 0.9919 - val_accuracy: 0.5686 - val_loss: 0.8983 - learning_rate: 2.0000e-04\n",
      "Epoch 3/15\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.5378 - loss: 0.9139 - val_accuracy: 0.5855 - val_loss: 0.8746 - learning_rate: 2.0000e-04\n",
      "Epoch 4/15\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.5764 - loss: 0.8709 - val_accuracy: 0.7334 - val_loss: 0.8512 - learning_rate: 2.0000e-04\n",
      "Epoch 5/15\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 52ms/step - accuracy: 0.5861 - loss: 0.8202 - val_accuracy: 0.7982 - val_loss: 0.8204 - learning_rate: 2.0000e-04\n",
      "Epoch 6/15\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - accuracy: 0.6293 - loss: 0.7763 - val_accuracy: 0.7966 - val_loss: 0.7789 - learning_rate: 2.0000e-04\n",
      "Epoch 7/15\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.6524 - loss: 0.7501 - val_accuracy: 0.8382 - val_loss: 0.7313 - learning_rate: 2.0000e-04\n",
      "Epoch 8/15\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.6641 - loss: 0.7112 - val_accuracy: 0.8644 - val_loss: 0.6774 - learning_rate: 2.0000e-04\n",
      "Epoch 9/15\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.7130 - loss: 0.6796 - val_accuracy: 0.8490 - val_loss: 0.6479 - learning_rate: 2.0000e-04\n",
      "Epoch 10/15\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.7166 - loss: 0.6576 - val_accuracy: 0.8582 - val_loss: 0.6205 - learning_rate: 2.0000e-04\n",
      "Epoch 11/15\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7414 - loss: 0.6184 - val_accuracy: 0.8706 - val_loss: 0.5918 - learning_rate: 2.0000e-04\n",
      "Epoch 12/15\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.7498 - loss: 0.6039 - val_accuracy: 0.8706 - val_loss: 0.5680 - learning_rate: 2.0000e-04\n",
      "Epoch 13/15\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - accuracy: 0.7822 - loss: 0.5659 - val_accuracy: 0.8737 - val_loss: 0.5385 - learning_rate: 2.0000e-04\n",
      "Epoch 14/15\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.7885 - loss: 0.5488 - val_accuracy: 0.8798 - val_loss: 0.5141 - learning_rate: 2.0000e-04\n",
      "Epoch 15/15\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.7994 - loss: 0.5306 - val_accuracy: 0.8891 - val_loss: 0.4841 - learning_rate: 2.0000e-04\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=64),  \n",
    "\n",
    "    GRU(16, activation=\"tanh\", return_sequences=True, \n",
    "         kernel_regularizer=l2(0.003), recurrent_dropout=0.5),  # Increased L2 and Dropout\n",
    "    Dropout(0.6),\n",
    "\n",
    "    GRU(8, kernel_regularizer=l2(0.003), recurrent_dropout=0.5, return_sequences=False),\n",
    "    Dropout(0.6),\n",
    "\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Dense(16, activation=\"relu\", kernel_regularizer=l2(0.003)),  # Increased L2\n",
    "    Dropout(0.7),  # Increased Dropout\n",
    "\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Compile with a lower learning rate\n",
    "optimizer = Adam(learning_rate=0.0002)  # Further reduced learning rate\n",
    "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Early Stopping (More aggressive stopping)\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=2,  # Decreased patience for early stopping\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.3,  # More aggressive reduction\n",
    "    patience=1,\n",
    "    min_lr=0.00005\n",
    ")\n",
    "\n",
    "# Train with adjusted dropout, regularization, and patience for early stopping\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=15,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8726 - loss: 0.4983\n",
      "Test accuracy: 0.8841\n",
      "\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8865 - loss: 0.4845\n",
      "Validation accuracy: 0.8891\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\\n\")\n",
    "\n",
    "val_loss, val_acc = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation accuracy: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 301ms/step\n",
      "Accuracy: 0.7125\n",
      "\n",
      "Misclassified Samples:\n",
      "    Label  Prediction Label_actual\n",
      "5   Human    0.101738           AI\n",
      "6   Human    0.361020           AI\n",
      "9   Human    0.257932           AI\n",
      "12  Human    0.332061           AI\n",
      "13  Human    0.258429           AI\n",
      "15     AI    0.612618        Human\n",
      "22  Human    0.269079           AI\n",
      "24  Human    0.216066           AI\n",
      "28  Human    0.441210           AI\n",
      "33  Human    0.476455           AI\n",
      "36     AI    0.591288        Human\n",
      "38  Human    0.402031           AI\n",
      "39  Human    0.321272           AI\n",
      "42  Human    0.300596           AI\n",
      "43  Human    0.441112           AI\n",
      "46     AI    0.655020        Human\n",
      "48     AI    0.720089        Human\n",
      "51  Human    0.278061           AI\n",
      "57  Human    0.463407           AI\n",
      "59  Human    0.342313           AI\n",
      "69  Human    0.226644           AI\n",
      "71  Human    0.429430           AI\n",
      "79  Human    0.256309           AI\n"
     ]
    }
   ],
   "source": [
    "# Load new data\n",
    "new_data = pd.read_csv(\"../../datasets/validation_dataset.csv\", delimiter=\";\")\n",
    "\n",
    "# Tokenize and pad the new data (using the same tokenizer you trained on)\n",
    "X_new_seq = tokenizer.texts_to_sequences(new_data[\"Text\"])\n",
    "X_new = pad_sequences(X_new_seq, maxlen=100)  # Ensure maxlen is consistent with your training data\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_new).flatten()\n",
    "\n",
    "# Convert predictions to labels based on threshold\n",
    "labels = [\"AI\" if pred > 0.5 else \"Human\" for pred in predictions]\n",
    "\n",
    "# Create output DataFrame with predictions\n",
    "output_df = pd.DataFrame({\n",
    "    \"Label\": labels,\n",
    "    \"Prediction\": predictions\n",
    "})\n",
    "\n",
    "# Load the ground truth labels (from the same dataset)\n",
    "# Since the labels are in the 'Label' column, we'll compare them with predictions.\n",
    "ground_truth = new_data[\"Label\"]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (output_df[\"Label\"] == ground_truth).mean()\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Merge predictions with ground truth for comparison\n",
    "comparison_df = output_df.copy()\n",
    "comparison_df[\"Label_actual\"] = ground_truth\n",
    "\n",
    "# Show misclassified samples\n",
    "misclassified = comparison_df[comparison_df[\"Label\"] != comparison_df[\"Label_actual\"]]\n",
    "print(\"\\nMisclassified Samples:\")\n",
    "print(misclassified)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
