{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recurrent_neural_net import RecurrentNeuralNetwork\n",
    "from tokenizer import  AdvancedTokenizer, RobustTokenizer, SimpleTokenizer\n",
    "from data import read_csv, read_csv_once\n",
    "from activation import SigmoidActivation, ReLUActivation\n",
    "from layers import DenseLayer, EmbeddingLayer, DropoutLayer, BatchNormalizationLayer, RNNLayer\n",
    "from losses import BinaryCrossEntropy   \n",
    "from metrics import accuracy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = '../../../datasets/final_dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing csv...\n",
      "CSV tokenized!\n",
      "Created model architecture\n",
      "Added layers to model\n",
      "\n",
      "Epoch 1/1\n",
      "Epoch 1/1 - loss: 0.7143 - accuracy: 0.5066 - val_loss: 0.7060 - val_accuracy: 0.4811\n",
      "Model trained\n",
      "Accuracy no dataset de teste: 0.4828\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Tokenizing csv...\")\n",
    "tokenizer = SimpleTokenizer(num_words=10000)\n",
    "print(\"CSV tokenized!\")\n",
    "train_data, validation_data, test_data = read_csv(csv, tokenizer)\n",
    "# Creating a RNN model\n",
    "rnn = RecurrentNeuralNetwork(\n",
    "    epochs=1,\n",
    "    batch_size=32,\n",
    "    learning_rate=0.01,\n",
    "    momentum=0.9,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print('Created model architecture')\n",
    "n_features = train_data.X.shape[1]\n",
    "# Build RNN architecture\n",
    "rnn.add(EmbeddingLayer(vocab_size=10000, embedding_dim=8, input_shape=(n_features,)))\n",
    "rnn.add(RNNLayer(32, return_sequences=True, bptt_trunc=None))\n",
    "rnn.add(RNNLayer(16, return_sequences=False, bptt_trunc=None))\n",
    "rnn.add(BatchNormalizationLayer())\n",
    "rnn.add(ReLUActivation())\n",
    "rnn.add(DropoutLayer(dropout_rate=0.3))\n",
    "rnn.add(DenseLayer(8))\n",
    "rnn.add(ReLUActivation())\n",
    "rnn.add(DenseLayer(1))\n",
    "rnn.add(SigmoidActivation())\n",
    "print('Added layers to model')\n",
    "\n",
    "# Train the model\n",
    "rnn.fit(train_data, validation_data=validation_data, patience=5)\n",
    "print('Model trained')\n",
    "\n",
    "test_predictions = rnn.predict(test_data)\n",
    "test_score = rnn.score(test_data, test_predictions)\n",
    "print(f\"Accuracy no dataset de teste: {test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4875\n",
      "   Label  Prediction Label_actual\n",
      "0     AI    0.557933        Human\n",
      "1     AI    0.557937        Human\n",
      "2     AI    0.557555           AI\n",
      "3     AI    0.557938        Human\n",
      "4     AI    0.557930        Human\n",
      "5     AI    0.557685           AI\n",
      "6     AI    0.557729           AI\n",
      "7     AI    0.557919        Human\n",
      "8     AI    0.557936        Human\n",
      "9     AI    0.557932           AI\n",
      "10    AI    0.557907           AI\n",
      "11    AI    0.557728           AI\n",
      "12    AI    0.557937           AI\n",
      "13    AI    0.557933           AI\n",
      "14    AI    0.557937        Human\n",
      "15    AI    0.557847        Human\n",
      "16    AI    0.557824           AI\n",
      "17    AI    0.557938        Human\n",
      "18    AI    0.557653           AI\n",
      "19    AI    0.557527        Human\n",
      "20    AI    0.557117        Human\n",
      "21    AI    0.557868        Human\n",
      "22    AI    0.557936           AI\n",
      "23    AI    0.557895        Human\n",
      "24    AI    0.557849           AI\n",
      "25    AI    0.557821        Human\n",
      "26    AI    0.557622        Human\n",
      "27    AI    0.557554        Human\n",
      "28    AI    0.557934           AI\n",
      "29    AI    0.557921        Human\n",
      "30    AI    0.556140        Human\n",
      "31    AI    0.557320        Human\n",
      "32    AI    0.557745        Human\n",
      "33    AI    0.557860           AI\n",
      "34    AI    0.557938           AI\n",
      "35    AI    0.557937           AI\n",
      "36    AI    0.557936        Human\n",
      "37    AI    0.557936           AI\n",
      "38    AI    0.557892           AI\n",
      "39    AI    0.557936           AI\n",
      "40    AI    0.557908           AI\n",
      "41    AI    0.557321        Human\n",
      "42    AI    0.557866           AI\n",
      "43    AI    0.557626           AI\n",
      "44    AI    0.556782           AI\n",
      "45    AI    0.557852           AI\n",
      "46    AI    0.557908        Human\n",
      "47    AI    0.557938        Human\n",
      "48    AI    0.557928        Human\n",
      "49    AI    0.557573        Human\n",
      "50    AI    0.557938        Human\n",
      "51    AI    0.557938           AI\n",
      "52    AI    0.557763        Human\n",
      "53    AI    0.557924           AI\n",
      "54    AI    0.557938        Human\n",
      "55    AI    0.557938           AI\n",
      "56    AI    0.557806        Human\n",
      "57    AI    0.557937           AI\n",
      "58    AI    0.557938        Human\n",
      "59    AI    0.556964           AI\n",
      "60    AI    0.557935        Human\n",
      "61    AI    0.557806           AI\n",
      "62    AI    0.557253        Human\n",
      "63    AI    0.557938           AI\n",
      "64    AI    0.557938        Human\n",
      "65    AI    0.557305           AI\n",
      "66    AI    0.557848        Human\n",
      "67    AI    0.557798           AI\n",
      "68    AI    0.557630        Human\n",
      "69    AI    0.557872           AI\n",
      "70    AI    0.557775        Human\n",
      "71    AI    0.557938           AI\n",
      "72    AI    0.557938        Human\n",
      "73    AI    0.557650           AI\n",
      "74    AI    0.557302        Human\n",
      "75    AI    0.557859           AI\n",
      "76    AI    0.557630        Human\n",
      "77    AI    0.557938           AI\n",
      "78    AI    0.557440        Human\n",
      "79    AI    0.557877           AI\n"
     ]
    }
   ],
   "source": [
    "file = pd.read_csv(\"../../../datasets/validation_dataset.csv\", sep=\";\")\n",
    "new_file = pd.DataFrame()\n",
    "# Mapear labels\n",
    "category_mapping = {\"Human\": 0, \"AI\": 1, \"student\": 0}\n",
    "new_file[\"Text\"] = file[\"Text\"]\n",
    "new_file[\"Label\"] = file[\"Label\"].map(category_mapping)\n",
    "\n",
    "# Processar os dados para a rede\n",
    "new_data = read_csv_once(new_file, tokenizer)\n",
    "\n",
    "# Fazer previsões\n",
    "predictions = rnn.predict(new_data)\n",
    "predictions = np.squeeze(predictions)\n",
    "\n",
    "# Converter previsões em rótulos\n",
    "labels = [\"AI\" if pred > 0.5 else \"Human\" for pred in predictions]\n",
    "\n",
    "# Criar DataFrame com previsões\n",
    "output_df = pd.DataFrame({\n",
    "    \"Label\": labels,\n",
    "    \"Prediction\": predictions\n",
    "})\n",
    "\n",
    "\n",
    "# Carregar os rótulos reais e convertê-los para strings\n",
    "ground_truth = file[\"Label\"]\n",
    "\n",
    "# Calcular precisão\n",
    "accuracys = (output_df[\"Label\"] == ground_truth).mean()\n",
    "\n",
    "# Imprimir precisão\n",
    "print(f\"Accuracy: {accuracys:.4f}\")\n",
    "\n",
    "# Comparar previsões com rótulos reais\n",
    "output_df[\"Label_actual\"] = ground_truth\n",
    "\n",
    "print(output_df)\n",
    "\n",
    "## Mostrar amostras mal classificadas\n",
    "#misclassified = output_df[output_df[\"Label\"] != output_df[\"Label_actual\"]]\n",
    "#print(\"\\nMisclassified Samples:\")\n",
    "#print(misclassified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
