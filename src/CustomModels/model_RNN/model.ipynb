{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recurrent_neural_net import RecurrentNeuralNetwork\n",
    "from tokenizer import  AdvancedTokenizer, RobustTokenizer, SimpleTokenizer\n",
    "from data import read_csv, read_csv_once\n",
    "from activation import SigmoidActivation, ReLUActivation\n",
    "from layers import DenseLayer, EmbeddingLayer, DropoutLayer, BatchNormalizationLayer, RNNLayer\n",
    "from losses import BinaryCrossEntropy   \n",
    "from metrics import accuracy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = '../../../datasets/final_dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_SEED = 42\n",
    "random.seed(GLOBAL_SEED)\n",
    "np.random.seed(GLOBAL_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 10000 \n",
    "EMBEDDING_DIM = 100 \n",
    "LEARNING_RATE = 0.0001\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "print(\"Tokenizing csv...\")\n",
    "tokenizer = SimpleTokenizer(num_words=10000, seed=GLOBAL_SEED)\n",
    "print(\"CSV tokenized!\")\n",
    "train_data, validation_data, test_data = read_csv(csv, tokenizer, seed=GLOBAL_SEED)\n",
    "# Creating a RNN model\n",
    "rnn = RecurrentNeuralNetwork(\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    momentum=0.9,\n",
    "    verbose=True,\n",
    "    seed=GLOBAL_SEED\n",
    ")\n",
    "\n",
    "print('Created model architecture')\n",
    "n_features = train_data.X.shape[1]\n",
    "# Build RNN architecture\n",
    "rnn.add(EmbeddingLayer(vocab_size=VOCAB_SIZE, embedding_dim=EMBEDDING_DIM, input_shape=(n_features,)))\n",
    "rnn.add(RNNLayer(128, return_sequences=False, bptt_trunc=None)) \n",
    "rnn.add(DropoutLayer(dropout_rate=0.5))\n",
    "rnn.add(DenseLayer(1))\n",
    "rnn.add(SigmoidActivation())\n",
    "print('Added layers to model')\n",
    "\n",
    "# Train the model\n",
    "rnn.fit(train_data, validation_data=validation_data, patience=5)\n",
    "print('Model trained')\n",
    "\n",
    "test_predictions = rnn.predict(test_data)\n",
    "test_score = rnn.score(test_data, test_predictions)\n",
    "print(f\"Accuracy no dataset de teste: {test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv(\"../../../datasets/validation_dataset.csv\", sep=\";\")\n",
    "new_file = pd.DataFrame()\n",
    "# Mapear labels\n",
    "category_mapping = {\"Human\": 0, \"AI\": 1, \"student\": 0}\n",
    "new_file[\"Text\"] = file[\"Text\"]\n",
    "new_file[\"Label\"] = file[\"Label\"].map(category_mapping)\n",
    "\n",
    "# Processar os dados para a rede\n",
    "new_data = read_csv_once(new_file, tokenizer, seed=GLOBAL_SEED)\n",
    "\n",
    "# Fazer previsões\n",
    "predictions = rnn.predict(new_data)\n",
    "predictions = np.squeeze(predictions)\n",
    "\n",
    "# Converter previsões em rótulos\n",
    "labels = [\"AI\" if pred > 0.5 else \"Human\" for pred in predictions]\n",
    "\n",
    "# Criar DataFrame com previsões\n",
    "output_df = pd.DataFrame({\n",
    "    \"Label\": labels,\n",
    "    \"Prediction\": predictions\n",
    "})\n",
    "\n",
    "\n",
    "# Carregar os rótulos reais e convertê-los para strings\n",
    "ground_truth = file[\"Label\"]\n",
    "\n",
    "# Calcular precisão\n",
    "accuracys = (output_df[\"Label\"] == ground_truth).mean()\n",
    "\n",
    "# Imprimir precisão\n",
    "print(f\"Accuracy: {accuracys:.4f}\")\n",
    "\n",
    "# Comparar previsões com rótulos reais\n",
    "output_df[\"Label_actual\"] = ground_truth\n",
    "\n",
    "print(\"\\nPredictions:\")\n",
    "print(output_df)\n",
    "\n",
    "## Mostrar amostras mal classificadas\n",
    "#misclassified = output_df[output_df[\"Label\"] != output_df[\"Label_actual\"]]\n",
    "#print(\"\\nMisclassified Samples:\")\n",
    "#print(misclassified)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
