{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recurrent_neural_net import RecurrentNeuralNetwork\n",
    "from tokenizer import  AdvancedTokenizer, RobustTokenizer, SimpleTokenizer\n",
    "from data import read_csv, read_csv_once\n",
    "from activation import SigmoidActivation, ReLUActivation\n",
    "from layers import DenseLayer, EmbeddingLayer, DropoutLayer, BatchNormalizationLayer, RNNLayer, LSTMLayer\n",
    "from losses import BinaryCrossEntropy   \n",
    "from metrics import accuracy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = '../../../datasets/final_dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_SEED = 42\n",
    "random.seed(GLOBAL_SEED)\n",
    "np.random.seed(GLOBAL_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing csv...\n",
      "CSV tokenized!\n",
      "Created model architecture\n",
      "Added layers to model\n",
      "\n",
      "Epoch 1/10\n",
      "Epoch 1/10 - loss: 3.2933 - accuracy: 0.4710 - val_loss: 0.6899 - val_accuracy: 0.5189\n",
      "\n",
      "Epoch 2/10\n",
      "Epoch 2/10 - loss: 0.6938 - accuracy: 0.5613 - val_loss: 0.6727 - val_accuracy: 0.5980\n",
      "\n",
      "Epoch 3/10\n",
      "Epoch 3/10 - loss: 0.6891 - accuracy: 0.5748 - val_loss: 0.6703 - val_accuracy: 0.6145\n",
      "\n",
      "Epoch 4/10\n",
      "Epoch 4/10 - loss: 0.6834 - accuracy: 0.5870 - val_loss: 0.6386 - val_accuracy: 0.6409\n",
      "\n",
      "Epoch 5/10\n",
      "Epoch 5/10 - loss: 0.6297 - accuracy: 0.6189 - val_loss: 0.6728 - val_accuracy: 0.6540\n",
      "\n",
      "Epoch 6/10\n",
      "Epoch 6/10 - loss: 0.5996 - accuracy: 0.6419 - val_loss: 0.7039 - val_accuracy: 0.6689\n",
      "\n",
      "Epoch 7/10\n",
      "Epoch 7/10 - loss: 0.5636 - accuracy: 0.6686 - val_loss: 0.6875 - val_accuracy: 0.6722\n",
      "\n",
      "Epoch 8/10\n",
      "Epoch 8/10 - loss: 0.5381 - accuracy: 0.6895 - val_loss: 0.6733 - val_accuracy: 0.6738\n",
      "\n",
      "Epoch 9/10\n",
      "Epoch 9/10 - loss: 0.5169 - accuracy: 0.7037 - val_loss: 0.7163 - val_accuracy: 0.6755\n",
      "\n",
      "Epoch 10/10\n",
      "Epoch 10/10 - loss: 0.5036 - accuracy: 0.7037 - val_loss: 0.7166 - val_accuracy: 0.6573\n",
      "Model trained\n",
      "Accuracy no dataset de teste: 0.7028\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = 10000 \n",
    "EMBEDDING_DIM = 100 \n",
    "LEARNING_RATE = 0.01\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "print(\"Tokenizing csv...\")\n",
    "tokenizer = SimpleTokenizer(num_words=10000, seed=GLOBAL_SEED)\n",
    "print(\"CSV tokenized!\")\n",
    "train_data, validation_data, test_data = read_csv(csv, tokenizer, seed=GLOBAL_SEED)\n",
    "# Creating a RNN model\n",
    "rnn = RecurrentNeuralNetwork(\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    momentum=0.9,\n",
    "    verbose=True,\n",
    "    seed=GLOBAL_SEED\n",
    ")\n",
    "\n",
    "\n",
    "print('Created model architecture')\n",
    "n_features = train_data.X.shape[1]\n",
    "# Build RNN architecture\n",
    "rnn.add(EmbeddingLayer(vocab_size=VOCAB_SIZE, embedding_dim=EMBEDDING_DIM, input_shape=(n_features,)))\n",
    "rnn.add(LSTMLayer(128, return_sequences=False, bptt_trunc=None))  \n",
    "rnn.add(BatchNormalizationLayer())\n",
    "rnn.add(DenseLayer(16))\n",
    "rnn.add(DenseLayer(1))\n",
    "print('Added layers to model')\n",
    "\n",
    "# Train the model\n",
    "rnn.fit(train_data, validation_data=validation_data, patience=10)\n",
    "print('Model trained')\n",
    "\n",
    "test_predictions = rnn.predict(test_data)\n",
    "test_score = rnn.score(test_data, test_predictions)\n",
    "print(f\"Accuracy no dataset de teste: {test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5375\n",
      "\n",
      "Predictions:\n",
      "    Label  Prediction Label_actual\n",
      "0   Human    0.457174        Human\n",
      "1   Human    0.444379        Human\n",
      "2      AI    0.516675           AI\n",
      "3   Human    0.442420        Human\n",
      "4   Human    0.451128        Human\n",
      "5   Human    0.447276           AI\n",
      "6   Human    0.464635           AI\n",
      "7   Human    0.467537        Human\n",
      "8   Human    0.449512        Human\n",
      "9   Human    0.448090           AI\n",
      "10  Human    0.475332           AI\n",
      "11  Human    0.496871           AI\n",
      "12  Human    0.452765           AI\n",
      "13  Human    0.464529           AI\n",
      "14  Human    0.444053        Human\n",
      "15     AI    0.516990        Human\n",
      "16  Human    0.494854           AI\n",
      "17  Human    0.461721        Human\n",
      "18     AI    0.513972           AI\n",
      "19     AI    0.534323        Human\n",
      "20  Human    0.478530        Human\n",
      "21  Human    0.443476        Human\n",
      "22  Human    0.446877           AI\n",
      "23  Human    0.472626        Human\n",
      "24  Human    0.475261           AI\n",
      "25     AI    0.508756        Human\n",
      "26     AI    0.508470        Human\n",
      "27  Human    0.415786        Human\n",
      "28  Human    0.453707           AI\n",
      "29  Human    0.455145        Human\n",
      "30     AI    0.515115        Human\n",
      "31  Human    0.473720        Human\n",
      "32  Human    0.492120        Human\n",
      "33     AI    0.506426           AI\n",
      "34  Human    0.443001           AI\n",
      "35  Human    0.447386           AI\n",
      "36  Human    0.453749        Human\n",
      "37  Human    0.461562           AI\n",
      "38  Human    0.497351           AI\n",
      "39  Human    0.449471           AI\n",
      "40  Human    0.490066           AI\n",
      "41  Human    0.486590        Human\n",
      "42  Human    0.485648           AI\n",
      "43     AI    0.514388           AI\n",
      "44     AI    0.526900           AI\n",
      "45  Human    0.499551           AI\n",
      "46  Human    0.490802        Human\n",
      "47  Human    0.439506        Human\n",
      "48  Human    0.467043        Human\n",
      "49  Human    0.464165        Human\n",
      "50  Human    0.440950        Human\n",
      "51  Human    0.440829           AI\n",
      "52  Human    0.478329        Human\n",
      "53  Human    0.490536           AI\n",
      "54  Human    0.440901        Human\n",
      "55  Human    0.442110           AI\n",
      "56     AI    0.535073        Human\n",
      "57  Human    0.444580           AI\n",
      "58  Human    0.440449        Human\n",
      "59     AI    0.503268           AI\n",
      "60  Human    0.458632        Human\n",
      "61     AI    0.521646           AI\n",
      "62  Human    0.403000        Human\n",
      "63  Human    0.442704           AI\n",
      "64  Human    0.441559        Human\n",
      "65     AI    0.584588           AI\n",
      "66  Human    0.474255        Human\n",
      "67  Human    0.493658           AI\n",
      "68  Human    0.425374        Human\n",
      "69  Human    0.469314           AI\n",
      "70  Human    0.473222        Human\n",
      "71  Human    0.439660           AI\n",
      "72  Human    0.441082        Human\n",
      "73  Human    0.484070           AI\n",
      "74     AI    0.516956        Human\n",
      "75     AI    0.539649           AI\n",
      "76  Human    0.488913        Human\n",
      "77  Human    0.445183           AI\n",
      "78  Human    0.495781        Human\n",
      "79  Human    0.481174           AI\n"
     ]
    }
   ],
   "source": [
    "file = pd.read_csv(\"../../../datasets/validation_dataset.csv\", sep=\";\")\n",
    "new_file = pd.DataFrame()\n",
    "# Mapear labels\n",
    "category_mapping = {\"Human\": 0, \"AI\": 1, \"student\": 0}\n",
    "new_file[\"Text\"] = file[\"Text\"]\n",
    "new_file[\"Label\"] = file[\"Label\"].map(category_mapping)\n",
    "\n",
    "# Processar os dados para a rede\n",
    "new_data = read_csv_once(new_file, tokenizer, seed=GLOBAL_SEED)\n",
    "\n",
    "# Fazer previsões\n",
    "predictions = rnn.predict(new_data)\n",
    "predictions = np.squeeze(predictions)\n",
    "\n",
    "# Converter previsões em rótulos\n",
    "labels = [\"AI\" if pred > 0.5 else \"Human\" for pred in predictions]\n",
    "\n",
    "# Criar DataFrame com previsões\n",
    "output_df = pd.DataFrame({\n",
    "    \"Label\": labels,\n",
    "    \"Prediction\": predictions\n",
    "})\n",
    "\n",
    "\n",
    "# Carregar os rótulos reais e convertê-los para strings\n",
    "ground_truth = file[\"Label\"]\n",
    "\n",
    "# Calcular precisão\n",
    "accuracys = (output_df[\"Label\"] == ground_truth).mean()\n",
    "\n",
    "# Imprimir precisão\n",
    "print(f\"Accuracy: {accuracys:.4f}\")\n",
    "\n",
    "# Comparar previsões com rótulos reais\n",
    "output_df[\"Label_actual\"] = ground_truth\n",
    "\n",
    "print(\"\\nPredictions:\")\n",
    "print(output_df)\n",
    "\n",
    "## Mostrar amostras mal classificadas\n",
    "#misclassified = output_df[output_df[\"Label\"] != output_df[\"Label_actual\"]]\n",
    "#print(\"\\nMisclassified Samples:\")\n",
    "#print(misclassified)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
