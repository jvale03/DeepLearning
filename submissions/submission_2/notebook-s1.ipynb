{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv(\"../../datasets/final_dataset.csv\")\n",
    "\n",
    "# First split: train and test\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    dataset[\"Text\"], dataset[\"Label\"], test_size=0.2, random_state=42, stratify=dataset[\"Label\"]\n",
    ")\n",
    "\n",
    "# Second split: train and validation\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_texts, train_labels, test_size=0.2, random_state=42, stratify=train_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the data\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(train_texts)\n",
    "X_val_seq = tokenizer.texts_to_sequences(val_texts)\n",
    "X_test_seq = tokenizer.texts_to_sequences(test_texts)\n",
    "\n",
    "X_train = pad_sequences(X_train_seq, maxlen=100)\n",
    "X_val = pad_sequences(X_val_seq, maxlen=100)\n",
    "X_test = pad_sequences(X_test_seq, maxlen=100)\n",
    "\n",
    "y_train = np.array(train_labels)\n",
    "y_val = np.array(val_labels)\n",
    "y_test = np.array(test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 66ms/step - accuracy: 0.5262 - loss: 1.0683 - val_accuracy: 0.6579 - val_loss: 0.9509 - learning_rate: 2.0000e-04\n",
      "Epoch 2/15\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.5152 - loss: 1.0002 - val_accuracy: 0.7381 - val_loss: 0.9209 - learning_rate: 2.0000e-04\n",
      "Epoch 3/15\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 0.5674 - loss: 0.9013 - val_accuracy: 0.7550 - val_loss: 0.8910 - learning_rate: 2.0000e-04\n",
      "Epoch 4/15\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.6033 - loss: 0.8635 - val_accuracy: 0.8243 - val_loss: 0.8613 - learning_rate: 2.0000e-04\n",
      "Epoch 5/15\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.6235 - loss: 0.8037 - val_accuracy: 0.8737 - val_loss: 0.8239 - learning_rate: 2.0000e-04\n",
      "Epoch 6/15\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.6619 - loss: 0.7698 - val_accuracy: 0.8937 - val_loss: 0.7774 - learning_rate: 2.0000e-04\n",
      "Epoch 7/15\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.6902 - loss: 0.7348 - val_accuracy: 0.8937 - val_loss: 0.7298 - learning_rate: 2.0000e-04\n",
      "Epoch 8/15\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.7233 - loss: 0.6865 - val_accuracy: 0.8983 - val_loss: 0.6729 - learning_rate: 2.0000e-04\n",
      "Epoch 9/15\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.7453 - loss: 0.6379 - val_accuracy: 0.9076 - val_loss: 0.6236 - learning_rate: 2.0000e-04\n",
      "Epoch 10/15\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.7466 - loss: 0.6308 - val_accuracy: 0.9307 - val_loss: 0.5716 - learning_rate: 2.0000e-04\n",
      "Epoch 11/15\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 69ms/step - accuracy: 0.8181 - loss: 0.5670 - val_accuracy: 0.9214 - val_loss: 0.5341 - learning_rate: 2.0000e-04\n",
      "Epoch 12/15\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 0.8006 - loss: 0.5494 - val_accuracy: 0.9368 - val_loss: 0.4935 - learning_rate: 2.0000e-04\n",
      "Epoch 13/15\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.8256 - loss: 0.5166 - val_accuracy: 0.9399 - val_loss: 0.4616 - learning_rate: 2.0000e-04\n",
      "Epoch 14/15\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.8420 - loss: 0.4965 - val_accuracy: 0.9492 - val_loss: 0.4249 - learning_rate: 2.0000e-04\n",
      "Epoch 15/15\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.8386 - loss: 0.4803 - val_accuracy: 0.9522 - val_loss: 0.4009 - learning_rate: 2.0000e-04\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=64),  \n",
    "\n",
    "    LSTM(16, activation=\"tanh\", return_sequences=True, \n",
    "         kernel_regularizer=l2(0.003), recurrent_dropout=0.5),  # Increased L2 and Dropout\n",
    "    Dropout(0.6),\n",
    "\n",
    "    LSTM(8, kernel_regularizer=l2(0.003), recurrent_dropout=0.5, return_sequences=False),\n",
    "    Dropout(0.6),\n",
    "\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Dense(16, activation=\"relu\", kernel_regularizer=l2(0.003)),  # Increased L2\n",
    "    Dropout(0.7),  # Increased Dropout\n",
    "\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Compile with a lower learning rate\n",
    "optimizer = Adam(learning_rate=0.0002)  # Further reduced learning rate\n",
    "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Early Stopping (More aggressive stopping)\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=2,  # Decreased patience for early stopping\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.3,  # More aggressive reduction\n",
    "    patience=1,\n",
    "    min_lr=0.00005\n",
    ")\n",
    "\n",
    "# Train with adjusted dropout, regularization, and patience for early stopping\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=15,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9381 - loss: 0.4109\n",
      "Test accuracy: 0.9433\n",
      "\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9489 - loss: 0.3984\n",
      "Validation accuracy: 0.9522\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\\n\")\n",
    "\n",
    "val_loss, val_acc = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation accuracy: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 231ms/step\n",
      "Accuracy: 0.7375\n",
      "\n",
      "Misclassified Samples:\n",
      "    Label  Prediction Label_actual\n",
      "5   Human    0.124157           AI\n",
      "6   Human    0.126704           AI\n",
      "9   Human    0.240882           AI\n",
      "11  Human    0.411136           AI\n",
      "12  Human    0.140583           AI\n",
      "13  Human    0.105954           AI\n",
      "22  Human    0.146398           AI\n",
      "24  Human    0.233467           AI\n",
      "28  Human    0.330795           AI\n",
      "38  Human    0.467187           AI\n",
      "39  Human    0.324959           AI\n",
      "42  Human    0.305147           AI\n",
      "48     AI    0.749000        Human\n",
      "51  Human    0.202729           AI\n",
      "54     AI    0.609120        Human\n",
      "57  Human    0.281737           AI\n",
      "59  Human    0.420288           AI\n",
      "67  Human    0.467878           AI\n",
      "69  Human    0.363551           AI\n",
      "75  Human    0.472127           AI\n",
      "79  Human    0.206749           AI\n"
     ]
    }
   ],
   "source": [
    "# Load new data\n",
    "new_data = pd.read_csv(\"../../datasets/validation_dataset.csv\", delimiter=\";\")\n",
    "\n",
    "# Tokenize and pad the new data (using the same tokenizer you trained on)\n",
    "X_new_seq = tokenizer.texts_to_sequences(new_data[\"Text\"])\n",
    "X_new = pad_sequences(X_new_seq, maxlen=100)  # Ensure maxlen is consistent with your training data\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_new).flatten()\n",
    "\n",
    "# Convert predictions to labels based on threshold\n",
    "labels = [\"AI\" if pred > 0.5 else \"Human\" for pred in predictions]\n",
    "\n",
    "# Create output DataFrame with predictions\n",
    "output_df = pd.DataFrame({\n",
    "    \"Label\": labels,\n",
    "    \"Prediction\": predictions\n",
    "})\n",
    "\n",
    "# Load the ground truth labels (from the same dataset)\n",
    "# Since the labels are in the 'Label' column, we'll compare them with predictions.\n",
    "ground_truth = new_data[\"Label\"]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (output_df[\"Label\"] == ground_truth).mean()\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Merge predictions with ground truth for comparison\n",
    "comparison_df = output_df.copy()\n",
    "comparison_df[\"Label_actual\"] = ground_truth\n",
    "\n",
    "# Show misclassified samples\n",
    "misclassified = comparison_df[comparison_df[\"Label\"] != comparison_df[\"Label_actual\"]]\n",
    "print(\"\\nMisclassified Samples:\")\n",
    "print(misclassified)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    }
   ],
   "source": [
    "# Load new dataset for prediction\n",
    "new_text_data = pd.read_csv(\"../../datasets/dataset3_inputs.csv\", delimiter=\";\")\n",
    "\n",
    "# Tokenize and pad the new text data\n",
    "X_new_seq = tokenizer.texts_to_sequences(new_text_data[\"Text\"])\n",
    "X_new = pad_sequences(X_new_seq, maxlen=100)  # Ensure maxlen is consistent with training data\n",
    "\n",
    "# Make predictions\n",
    "new_predictions = model.predict(X_new).flatten()\n",
    "\n",
    "# Convert predictions to labels based on threshold\n",
    "new_labels = [\"AI\" if pred > 0.5 else \"Human\" for pred in new_predictions]\n",
    "\n",
    "# Create output DataFrame with ID and predictions\n",
    "output_new_df = pd.DataFrame({\n",
    "    \"ID\": new_text_data[\"ID\"],\n",
    "    \"Label\": new_labels\n",
    "})\n",
    "\n",
    "# Save the predictions to a new CSV file\n",
    "output_new_df.to_csv(\"results-s1.csv\", sep=\";\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
