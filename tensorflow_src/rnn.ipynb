{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dropout, Dense, ReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "dataset = pd.read_csv(\"../datasets/AI_Human.csv\")\n",
    "\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    dataset[\"text\"], dataset[\"generated\"], test_size=0.2, random_state=42, stratify=dataset[\"generated\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "X_train = vectorizer.fit_transform(train_texts).toarray()\n",
    "X_test = vectorizer.fit_transform(test_texts).toarray()\n",
    "\n",
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max(len(seq) for seq in X_train) \n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.Input(shape=(max_length,)))\n",
    "\n",
    "embedding_dim = 32\n",
    "vocab_size = 5000\n",
    "model.add(keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim))\n",
    "model.add(keras.layers.Bidirectional(keras.layers.SimpleRNN(32, activation='tanh')))\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(1))\n",
    "\n",
    "loss = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "optim = keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "metrics = [\"accuracy\"]\n",
    "\n",
    "model.compile(loss=loss, optimizer=optim, metrics=metrics)\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 1\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "model.save('../models/model_RNN_tf.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load new data\n",
    "new_data = pd.read_csv(\"dataset_inputs.csv\", delimiter=\"\\t\")  # Ensure correct delimiter\n",
    "\n",
    "# Transform text using the same vectorizer\n",
    "X_new = vectorizer.transform(new_data[\"Text\"]).toarray()  # Ensure column name matches\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_new).flatten()  # Get raw prediction values\n",
    "\n",
    "# Convert predictions to labels\n",
    "labels = [\"AI\" if pred > 0.5 else \"Human\" for pred in predictions]\n",
    "\n",
    "# Create output DataFrame with both predicted labels and raw prediction values\n",
    "output_df = pd.DataFrame({\"ID\": new_data[\"ID\"], \"Label\": labels, \"Prediction\": predictions})\n",
    "\n",
    "# Save to TSV (tab-separated file)\n",
    "output_df.to_csv(\"predictions_output.csv\", index=False, sep=\"\\t\")\n",
    "\n",
    "print(\"Predictions saved to predictions_output.tsv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the correct labels (ground truth)\n",
    "ground_truth = pd.read_csv(\"dataset_outputs.csv\", delimiter=\"\\t\")  # Ensure it's tab-separated\n",
    "\n",
    "# Load the predictions\n",
    "predictions = pd.read_csv(\"predictions_output.csv\", delimiter=\"\\t\")\n",
    "\n",
    "# Merge the two datasets on \"ID\" to align predictions with correct labels\n",
    "comparison_df = predictions.merge(ground_truth, on=\"ID\", suffixes=(\"_predicted\", \"_actual\"))\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (comparison_df[\"Label_predicted\"] == comparison_df[\"Label_actual\"]).mean()\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Show misclassified samples\n",
    "misclassified = comparison_df[comparison_df[\"Label_predicted\"] != comparison_df[\"Label_actual\"]]\n",
    "print(\"\\nMisclassified Samples:\")\n",
    "print(misclassified)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
